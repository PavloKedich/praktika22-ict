import logging
import threading
import asyncio
import tkinter as tk
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI, OpenAIError

# --- –¢–æ–∫–µ–Ω–∏ ---
TELEGRAM_BOT_TOKEN = "your_telegram_bot_token"
OPENAI_API_KEY = "your_openrouter_api_key"

# --- OpenRouter –∫–ª—ñ—î–Ω—Ç ---
client = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url="https://openrouter.ai/api/v1"
)

# --- GUI –¥–ª—è –ª–æ–≥—ñ–≤ ---
class LogWindow:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Telegram GPT –õ–æ–≥–∏")
        self.root.geometry("700x500")
        self.text = tk.Text(self.root, wrap="word", state="disabled", bg="#1e1e1e", fg="#00ff00", font=("Consolas", 11))
        self.text.pack(fill="both", expand=True)

    def log(self, message: str):
        self.text.config(state="normal")
        self.text.insert(tk.END, message + "\n")
        self.text.see(tk.END)
        self.text.config(state="disabled")

    def start(self):
        self.root.mainloop()

log_window = LogWindow()

# --- –û–±—Ä–æ–±–∫–∞ –∫–æ–º–∞–Ω–¥ ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üëã –ü—Ä–∏–≤—ñ—Ç! –Ø –±–æ—Ç GPT. –ù–∞–ø–∏—à–∏ —â–æ—Å—å –∞–±–æ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Å—è –∫–æ–º–∞–Ω–¥–æ—é /code –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–æ–¥—É.")

# --- –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text.strip()
    user_name = update.effective_user.username or update.effective_user.first_name

    log_window.log(f"[{user_name}] –Ω–∞–ø–∏—Å–∞–≤: {user_text}")

    # --- –õ–æ–≥—ñ–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–æ–¥—É ---
    is_code_request = user_text.lower().startswith("–Ω–∞–ø–∏—à–∏ –∫–æ–¥") or user_text.lower().startswith("/code")

    prompt = user_text
    if is_code_request:
        prompt = f"–ù–∞–ø–∏—à–∏ –∫–æ–¥: {user_text.replace('/code', '').strip()}"

    try:
        response = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300 if is_code_request else 150,  # –ë—ñ–ª—å—à–µ –¥–ª—è –∫–æ–¥—É
            temperature=0.5
        )
        answer = response.choices[0].message.content
    except OpenAIError as e:
        error_text = f"‚ùå –ü–æ–º–∏–ª–∫–∞ API: {e}"
        log_window.log(error_text)
        await update.message.reply_text("‚ö†Ô∏è –°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–≤–µ—Ä–Ω–µ–Ω–Ω—ñ –¥–æ GPT. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.")
        return

    log_window.log(f"[GPT] –≤—ñ–¥–ø–æ–≤—ñ–≤: {answer}")
    await update.message.reply_text(answer)

# --- –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —É –ø–æ—Ç–æ—Ü—ñ ---
def run_bot():
    asyncio.set_event_loop(asyncio.new_event_loop())
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    print("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–∏–π...")
    app.run_polling()

# --- –°—Ç–∞—Ä—Ç ---
if __name__ == "__main__":
    threading.Thread(target=run_bot, daemon=True).start()
    log_window.start()
